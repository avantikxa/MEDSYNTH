# MEDSYNTH: Medical Image Generation and Classification

## 1. Introduction

The MEDSYNTH project is dedicated to tackling the persistent challenges associated with limited and imbalanced medical imaging datasets, with a specific focus on the critical domain of brain tumor classification. In this comprehensive README, we present an in-depth exploration of our project, highlighting two core components: Image Classification utilizing Convolutional Neural Networks (CNNs) and the innovative application of Conditional Generative Adversarial Networks (cGANs).

Our groundbreaking approach within the MEDSYNTH project harnesses the power of conditional Generative Adversarial Networks (cGANs) to combat the widespread scarcity of medical imaging data, particularly within the realm of brain tumor classification. Through the generation of synthetic medical images grounded in existing datasets, our primary objective is to significantly enhance the performance and robustness of classification models. This README offers an extensive overview of our project's overarching goals, the methodologies employed, and the profound impact it promises to make in advancing the field of brain tumor classification, firmly situated within the landscape of Artificial Intelligence and Machine Learning (AI and ML).

## 2. Dataset and Preprocessing

In our research, we have utilized a medical imaging dataset comprising various types of brain tumor images. This dataset is characterized by its diversity, encompassing different tumor subtypes, sizes, and locations. Preprocessing techniques include data normalization, resizing, and augmentation to prepare the data for model training.

## 3. Image Classification with CNNs

### Our Approach: The ResNet50 Architecture

For image classification, we adopted the ResNet50 architecture, a powerful deep-learning model known for its ability to handle large medical image datasets effectively. We fine-tuned the pre-trained ResNet50 model to achieve optimal results for brain tumor classification.

### Appropriate Level of Transfer Learning

Transfer learning is a crucial aspect of our approach. We discuss the decision-making process for selecting the right layers to fine-tune, ensuring that our model captures both low-level and high-level features in the medical images.

### Our Classification Model

In this section, we provide details about the structure and parameters of our custom classification model built on top of the ResNet50 base model.

## 4. Conditional Generative Adversarial Networks

### An Overview on Generative Adversarial Networks (GANs):

Generative Adversarial Networks (GANs) are a class of deep learning models composed of two main components: the Discriminator and the Generator.

#### The Discriminator

The Discriminator in a GAN is a neural network responsible for distinguishing between real and generated data. It is trained to assign higher probabilities to real data and lower probabilities to fake data.

#### The Generator

The Generator, on the other hand, aims to produce synthetic data that is indistinguishable from real data. It learns to generate data samples that can fool the Discriminator into classifying them as real.

#### Minimax Loss

The training process of GANs involves a minimax game, where the Generator tries to minimize the loss while the Discriminator aims to maximize it. This adversarial training leads to the improvement of both components until an equilibrium is reached, resulting in high-quality generated data.

### What Are Conditional GANs?

Conditional GANs (cGANs) extend the concept of GANs by incorporating additional information, such as labels or context, to condition the data generation process. In our case, we use cGANs to generate synthetic medical images conditioned on the type of brain tumor.

## Our Approach to Conditional GANs: Using the [GANForge](https://github.com/quadeer15sh/GANForge/tree/main) Library
```python 
pip install git+https://github.com/quadeer15sh/GANForge.git
```


We have chosen the GANForge library to implement our cGAN model. This section provides insights into our choice of library and how it facilitates the creation of conditional GANs for medical image generation.

## Training Our Conditional GAN

Here, we outline the training procedure for our conditional GAN, including details about the hyperparameters, loss functions, and convergence criteria.

## Generating Images

We explain how we use the trained cGAN to generate synthetic medical images, focusing on the potential benefits of augmenting the classification dataset with these generated images.

## 5. Comparing Classification Outputs

### Classification Before Augmenting Data with Generated Images

We present the results of the image classification model before incorporating synthetic images generated by the cGAN. This serves as a baseline for evaluating the impact of data augmentation.

### Classification After Augmenting Data with Generated Images

In this section, we discuss the classification model's performance after augmenting the dataset with synthetic images. We compare the model's accuracy, sensitivity, specificity, and robustness with the baseline results to assess the benefits of data augmentation.

### Inference

We provide insights into the practical implications of our project, discussing how the integration of conditional GANs in medical image classification can improve the generalizability and robustness of AI-based diagnosis systems.
